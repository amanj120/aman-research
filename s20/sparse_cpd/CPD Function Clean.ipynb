{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore'); #tensorflow gives me weird stuff\n",
    "import numpy as np;\n",
    "import tensorflow as tf;\n",
    "from numpy import matmul as mul\n",
    "from numpy.linalg import norm as norm\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hadamard(matrices, skip_matrix = -1):\n",
    "    #matrices is a list of numpy ndarrays (shape of all matrices must be the same)\n",
    "    shp = matrices[0].shape\n",
    "    #Commented out for performance increase\n",
    "#     for m in matrices: \n",
    "#         if m.shape != shp:\n",
    "#             return None\n",
    "    ret = np.ones(shp)\n",
    "    for i in range(shp[0]):\n",
    "        for j in range(shp[1]):\n",
    "            for num,k in enumerate(matrices):\n",
    "                if(num != skip_matrix):\n",
    "                    ret[i][j] *= k[i][j]\n",
    "                    if ret[i][j] == 0: #just a lil optimization\n",
    "                        break;\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MTTKRP helper methods\n",
    "\n",
    "def calc_indices(t, dims, n):\n",
    "    #t is the target row we want (zero indexed)\n",
    "    #dims is the dimensions of the tensor\n",
    "    #n is the factor matrix we dont want to include\n",
    "    \n",
    "    #first get cumulative products on our factors\n",
    "    prods = [1]\n",
    "    nd = len(dims)\n",
    "    for i in range(nd-1,-1,-1):\n",
    "        if i!=n:\n",
    "            p = prods[-1] * dims[i]\n",
    "            prods.append(p)\n",
    "    prods.reverse()\n",
    "    prods = prods[1:]\n",
    "    ret = [] #the coefficients of the thingy we want\n",
    "    for i in range(nd - 1):\n",
    "        n = t // prods[i];\n",
    "        ret.append(n)\n",
    "        t -= (prods[i] * n)\n",
    "    return ret\n",
    "\n",
    "def khatri_rao_at_ij(factors, i, j, dims, n):\n",
    "    #dims is the list of dimensions, factors is the actual factor matrix, \n",
    "    #factors is the list of all factor matrices\n",
    "    #gives you the khatri rao product at a certain index\n",
    "    product = 1\n",
    "    i_vals = calc_indices(i, dims, n)\n",
    "    for num, factor in enumerate(factors):\n",
    "        if num == n:\n",
    "            pass\n",
    "        if num < n:\n",
    "            product *= factors[num][i_vals[num]][j]\n",
    "        if num > n:\n",
    "            product *= factors[num][i_vals[num-1]][j]\n",
    "    return product\n",
    "\n",
    "def find_index_unfolded(dims, n, idx):\n",
    "    #finds the coordinates of the unfolded tensor element given the coordinates of the not-unfolded tensor\n",
    "    j = 0;\n",
    "    nd = len(dims)\n",
    "    prod = 1;\n",
    "    \n",
    "    for i in range(nd):\n",
    "        if i != n:\n",
    "            j += idx[i] * prod\n",
    "            prod *= dims[i]\n",
    "    \n",
    "    return (idx[n], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MTTKRP(X, factors, weights, n,rank,dims):\n",
    "    # Matricized Tensor Times Khatri Rao Product\n",
    "    # X unfolded is short and fat, khatri-rao is tall and skinny\n",
    "    # output is short and skinny\n",
    "    \n",
    "    nd = len(dims)\n",
    "    output = np.zeros((dims[n],rank))\n",
    "    indices = X.indices.numpy()\n",
    "    values = X.values.numpy()\n",
    "    \n",
    "    for l in range(len(values)):\n",
    "        cur_index = indices[l]\n",
    "        cur_value = values[l]\n",
    "        i,j = find_index_unfolded(dims, n, cur_index) \n",
    "        # gets the index of this element if we did a mode n unfolding of X\n",
    "        \n",
    "        for r in range(rank):\n",
    "            output[i][r] += cur_value * khatri_rao_at_ij(factors,j,r,dims,n) * weights[0][r]\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_als(X, rank, iterations = 3):\n",
    "    \n",
    "    dims = X.shape.as_list()\n",
    "    nd = len(dims)\n",
    "    factors = [np.ones((d,rank)) for d in dims]\n",
    "    l = np.ones((1,rank))\n",
    "    \n",
    "    for iteration in range(iterations): \n",
    "        for n in range(nd):\n",
    "            to_be_hadamarded = [mul(f.T,f) for f in factors] + [mul(l.T,l)]\n",
    "            v = hadamard(to_be_hadamarded, skip_matrix=n)   \n",
    "            vinv = np.linalg.pinv(v)\n",
    "            mk = MTTKRP(X, factors, l, n, rank, dims)\n",
    "            An = mul(mk,vinv)\n",
    "            for i in range(rank):\n",
    "                col = An[:,i]\n",
    "                weight = norm(col)\n",
    "                # print( \" weight: \", weight, 'col: ', col)\n",
    "                if(abs(weight)> 0.000001):\n",
    "                    An[:,i]/=weight\n",
    "                    l[0][i]*=weight\n",
    "            factors[n] = An\n",
    "            \n",
    "    return l, factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[1,0,0],[1,0,1],[1,0,2],[1,1,0],[1,1,1],[1,1,2],[2,0,0],[2,0,1],[2,0,2],[2,1,0],[2,1,1],[2,1,2],[3,0,0],[3,0,1],[3,0,2],[3,1,0],[3,1,1],[3,1,2]]\n",
    "values = [16.0, 12.0, 10.0, 64.0, 48.0, 40.0, 24.0, 18.0, 15.0, 96.0, 72.0, 60.0, 56.0, 42.0, 35.0, 224.0, 168.0, 140.0]\n",
    "shape = [4,2,3]\n",
    "\n",
    "st = tf.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "tf.sparse.to_dense(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_rank = 1\n",
    "factors = cp_als(st, st_rank, 1000)\n",
    "factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(factors, weights, dim_no, cur_idx, cur_prod, all_vals, rank):\n",
    "    #this method just writes to all values, so all values needs to be saved somewhere\n",
    "    if dim_no == len(factors):\n",
    "        value = 0;\n",
    "        for r in range(rank):\n",
    "            value += cur_prod[r] * weights[0][r]\n",
    "        if(value != 0.0):\n",
    "            all_vals.append((cur_idx,value)) \n",
    "    else:\n",
    "        cur_fact = factors[dim_no]\n",
    "        for i in range(len(cur_fact)): # go through all rows\n",
    "            cp = np.ndarray.copy(cur_prod);\n",
    "            for r in range(rank): # go through each rank\n",
    "                cp[r] *= cur_fact[i][r]\n",
    "            expand(factors, weights, dim_no + 1, cur_idx + [i], cp, all_vals, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_sp_tensor_from_factors(factors, weights, dimensions, rank):\n",
    "    #print(factors)\n",
    "    all_values = []\n",
    "    expand(factors, weights, 0, [], np.ones(rank), all_values, rank)\n",
    "    #print(all_values)\n",
    "    indices = [a[0] for a in all_values]\n",
    "    values = [a[1] for a in all_values]\n",
    "    shape = dimensions\n",
    "    st = tf.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = rebuild_sp_tensor_from_factors(factors[1], factors[0], shape, st_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sparse.to_dense(rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sparse.to_dense(st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
