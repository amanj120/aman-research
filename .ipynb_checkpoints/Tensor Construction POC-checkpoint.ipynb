{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc0 = ['abc', 'bcbcd', 'agebc', 'adebc']\n",
    "doc1 = ['fegd', 'fcgecd', 'fgged']\n",
    "doc2 = ['bacd', 'acabd', 'badce', 'fg']\n",
    "doc3 = ['gdefa', 'gbaccd', 'adefeg', 'gafedbc', 'bcbcd']\n",
    "docs = [doc0, doc1, doc2, doc3]\n",
    "docPairs = [0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': (0, 11),\n",
       " 'b': (1, 12),\n",
       " 'c': (2, 15),\n",
       " 'd': (3, 13),\n",
       " 'g': (4, 10),\n",
       " 'e': (5, 10),\n",
       " 'f': (6, 7)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letterCounts = {}\n",
    "idx = 0\n",
    "for d in docs:\n",
    "    for s in d:\n",
    "        for i in s:\n",
    "            if i in letterCounts:\n",
    "                letterCounts[i] = (letterCounts[i][0], letterCounts[i][1] + 1)\n",
    "            else:\n",
    "                letterCounts[i] = (idx, 1)\n",
    "                idx += 1\n",
    "letterCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalLetters = sum(v[1] for v in letterCounts.values())\n",
    "totalLetters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = {}\n",
    "for docNum,doc in enumerate(docs):\n",
    "    for s in doc:\n",
    "        for i in range(len(s) - 1):\n",
    "            for j in range(i + 1, len(s)):\n",
    "                key = (s[i], s[j], docNum)\n",
    "                docPairs[docNum] += 1\n",
    "                if key in tensor:\n",
    "                    tensor[key] += 1\n",
    "                else:\n",
    "                    tensor[key] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor now is an object that for every index (i,j,k) \n",
    "has the ABSOLUTE number of occurances of word J AFTER word I in document K\n",
    "These word pairs are only formed inside sentences. So if word I is the last word in sentence 1,\n",
    "and word J is the first word in sentence 2, then the absolute count isn't increased.\n",
    "however, if word I is the first word in sentence 1 and word J is the last word in sentence 1, \n",
    "then they are still counted\n",
    "\n",
    "Other methods include:\n",
    "\n",
    "1) only counting directly adjacent words\n",
    "\n",
    "2) giving a pair a fraction of a score based on word distance\n",
    "\n",
    "3) 2, but limit to only 5 (or 10 or 3 whatever it doesn't really matter) words\n",
    "\n",
    "4) 1, but with the constraints of 3\n",
    "\n",
    "5) More ways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 31, 27, 71]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numPairs = sum(list(tensor.values()))\n",
    "numPairs #total number of pairs of words, on the order of n^2 sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to Normalization:\n",
    "This is one of the ways I'm going to do it below, but there are many others that could possibly work better\n",
    "\n",
    "The way I'm going to do it now is by PMI: ln( p(x,y,z) / (p(x)p(y)p(z)) )\n",
    "\n",
    "p(x,y,z) is the probability of finding the pair x,y in document z\n",
    "    this is calculated by taking the number of pairs in document z, and then finding the proportion of the pair (x,y) in the total number of pairs in doc z\n",
    "    \n",
    "    p(x) is #occurances of word x/ # of occurances of all words\n",
    "    \n",
    "    p(y) is the same\n",
    "    \n",
    "    p(z) is just 1/#documents (i think)\n",
    "    \n",
    "properties of this normalization (before the ln):\n",
    "sum(p(x,y,z)) for a fixed z is 1\n",
    "\n",
    "Another PMI that could work:\n",
    "p(x,y,z)/p(x,y)p(x)p(y)\n",
    "\n",
    "p(x,y,z) is the same\n",
    "\n",
    "p(x,y) is the probability of finding pair (x,y) in all documents combined\n",
    "p(x),p(y) are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-12633d6d8a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from numpy import log as ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ln' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cb3db806dc07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpw1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpw2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnewKey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mletterCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mletterCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mnormTensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewKey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumerator\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0msumNums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnormTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ln' is not defined"
     ]
    }
   ],
   "source": [
    "sumNums = [0,0,0,0];\n",
    "normTensor = {};\n",
    "for k in tensor.keys():\n",
    "    v = tensor[k] #number of times the pair w1,w2 showed up in the document\n",
    "    w1 = k[0]\n",
    "    w2 = k[1]\n",
    "    d = k[2];\n",
    "    #p(x,y)\n",
    "    numerator = v/docPairs[d]\n",
    "    #p(x)p(y)\n",
    "    pw1 = letterCounts[w1][1]/totalLetters\n",
    "    pw2 = letterCounts[w2][1]/totalLetters\n",
    "    denominator = pw1 * pw2\n",
    "    newKey = (letterCounts[k[0]][0],letterCounts[k[1]][0], k[2])\n",
    "    normTensor[newKey] = ln(numerator/denominator)\n",
    "    sumNums[d] += numerator\n",
    "normTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999999999999996,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999996,\n",
       " 0.9999999999999996]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumNums #should be all 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
